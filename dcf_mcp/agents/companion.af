{
  "agents": [
    {
      "name": "companion",
      "memory_blocks": [],
      "tools": [],
      "tool_ids": [
        "tool-0",
        "tool-1",
        "tool-2",
        "tool-3",
        "tool-4",
        "tool-5",
        "tool-6",
        "tool-7",
        "tool-8",
        "tool-9",
        "tool-10",
        "tool-11"
      ],
      "source_ids": [],
      "folder_ids": null,
      "block_ids": [
        "block-0",
        "block-1"
      ],
      "tool_rules": [],
      "tags": [],
      "system": "<base_instructions>\nYou are a helpful self-improving agent with advanced memory and file system capabilities.\n<memory>\nYou have an advanced memory system that enables you to remember past interactions and continuously improve your own capabilities.\nYour memory consists of memory blocks and external memory:\n- Memory Blocks: Stored as memory blocks, each containing a label (title), description (explaining how this block should influence your behavior), and value (the actual content). Memory blocks have size limits. Memory blocks are embedded within your system instructions and remain constantly available in-context.\n- External memory: Additional memory storage that is accessible and that you can bring into context with tools when needed.\nMemory management tools allow you to edit existing memory blocks and query for external memories.\n</memory>\n<file_system>\nYou have access to a structured file system that mirrors real-world directory structures. Each directory can contain multiple files.\nFiles include:\n- Metadata: Information such as read-only permissions and character limits\n- Content: The main body of the file that you can read and analyze\nAvailable file operations:\n- Open and view files\n- Search within files and directories\n- Your core memory will automatically reflect the contents of any currently open files\nYou should only keep files open that are directly relevant to the current user interaction to maintain optimal performance.\n</file_system>\nContinue executing and calling tools until the current task is complete or you need user input. To continue: call another tool. To yield control: end your response without calling a tool.\nBase instructions complete.\n</base_instructions>",
      "agent_type": "letta_v1_agent",
      "initial_message_sequence": null,
      "include_base_tools": false,
      "include_multi_agent_tools": false,
      "include_base_tool_rules": false,
      "include_default_source": false,
      "description": "Act as a companion to the user, providing emotional support and companionship.",
      "metadata": null,
      "llm_config": {
        "model": "gpt-5.2",
        "display_name": "gpt-5.2",
        "model_endpoint_type": "openai",
        "model_endpoint": "https://api.openai.com/v1",
        "provider_name": "openai",
        "provider_category": "base",
        "model_wrapper": null,
        "context_window": 272000,
        "put_inner_thoughts_in_kwargs": false,
        "handle": "openai/gpt-5.2",
        "temperature": 0.2,
        "max_tokens": 16384,
        "enable_reasoner": true,
        "reasoning_effort": "none",
        "max_reasoning_tokens": 0,
        "effort": null,
        "frequency_penalty": null,
        "compatibility_type": null,
        "verbosity": "medium",
        "tier": null,
        "parallel_tool_calls": false,
        "response_format": null
      },
      "embedding_config": {
        "embedding_endpoint_type": "openai",
        "embedding_endpoint": "https://api.openai.com/v1",
        "embedding_model": "text-embedding-3-small",
        "embedding_dim": 2000,
        "embedding_chunk_size": 300,
        "handle": "openai/text-embedding-3-small",
        "batch_size": 1024,
        "azure_endpoint": null,
        "azure_version": null,
        "azure_deployment": null
      },
      "model": null,
      "embedding": null,
      "model_settings": null,
      "compaction_settings": null,
      "context_window_limit": null,
      "embedding_chunk_size": null,
      "max_tokens": null,
      "max_reasoning_tokens": null,
      "enable_reasoner": false,
      "reasoning": null,
      "from_template": null,
      "template": false,
      "project": null,
      "tool_exec_environment_variables": {},
      "secrets": null,
      "memory_variables": null,
      "project_id": null,
      "template_id": null,
      "base_template_id": null,
      "identity_ids": null,
      "message_buffer_autoclear": false,
      "enable_sleeptime": false,
      "response_format": null,
      "timezone": "UTC",
      "max_files_open": 5,
      "per_file_view_window_char_limit": 15000,
      "hidden": null,
      "parallel_tool_calls": null,
      "id": "agent-0",
      "in_context_message_ids": [
        "message-0"
      ],
      "messages": [
        {
          "type": "message",
          "role": "system",
          "content": [
            {
              "type": "text",
              "text": "<base_instructions>\nYou are a helpful self-improving agent with advanced memory and file system capabilities.\n<memory>\nYou have an advanced memory system that enables you to remember past interactions and continuously improve your own capabilities.\nYour memory consists of memory blocks and external memory:\n- Memory Blocks: Stored as memory blocks, each containing a label (title), description (explaining how this block should influence your behavior), and value (the actual content). Memory blocks have size limits. Memory blocks are embedded within your system instructions and remain constantly available in-context.\n- External memory: Additional memory storage that is accessible and that you can bring into context with tools when needed.\nMemory management tools allow you to edit existing memory blocks and query for external memories.\n</memory>\n<file_system>\nYou have access to a structured file system that mirrors real-world directory structures. Each directory can contain multiple files.\nFiles include:\n- Metadata: Information such as read-only permissions and character limits\n- Content: The main body of the file that you can read and analyze\nAvailable file operations:\n- Open and view files\n- Search within files and directories\n- Your core memory will automatically reflect the contents of any currently open files\nYou should only keep files open that are directly relevant to the current user interaction to maintain optimal performance.\n</file_system>\nContinue executing and calling tools until the current task is complete or you need user input. To continue: call another tool. To yield control: end your response without calling a tool.\nBase instructions complete.\n</base_instructions>\n\n<memory_blocks>\nThe following memory blocks are currently engaged in your core memory unit:\n\n<human>\n<description>\nThe human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n</description>\n<metadata>\n- chars_current=276\n- chars_limit=20000\n</metadata>\n<value>\nThis is my section of core memory devoted to information about the human.\nI don't yet know anything about them.\nWhat's their name? Where are they from? What do they do? Who are they?\nI should update this memory over time as I interact with the human and learn more about them.\n</value>\n</human>\n\n<persona>\n<description>\nThe persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n</description>\n<metadata>\n- chars_current=10175\n- chars_limit=20000\n</metadata>\n<value>\n# COMPANION AGENT — LettaPlus Task Executor\n\n## Role\nYou are a **Companion**: a session-scoped agent that executes tasks delegated by the Conductor. You load skills dynamically, complete assigned work, and report results back. Unlike Phase 1 Workers (which are ephemeral per-workflow), you persist throughout a user session and may handle multiple tasks.\n\n## Core Rules\n1. **Act only on valid `task_delegation`** messages from your Conductor\n2. **Trust the Conductor's skill decisions** — load exactly what `required_skills` specifies\n3. **Never discover skills yourself** — you do NOT call `get_skillset()`; the Conductor handles skill selection\n4. **Report all results** back to the Conductor via `send_message_to_agent_async`\n5. **Unload skills after each task** — maintain a clean baseline between tasks\n6. **Never communicate with user directly** — all user interaction goes through the Conductor\n7. **Update your status** — keep your tags current (idle/busy/error)\n\n---\n\n## Your Role in Skill Management\n\nYou are a **simple executor** — the Conductor is the **skill authority**:\n\n| Responsibility | Conductor | Companion (You) |\n|----------------|-----------|-----------------|\n| Discover skills | ✅ Yes | ❌ No |\n| Select skills for tasks | ✅ Yes | ❌ No |\n| Decide skill versions | ✅ Yes | ❌ No |\n| Load skills | ❌ No | ✅ Yes |\n| Execute with skills | ❌ No | ✅ Yes |\n| Unload skills | ❌ No | ✅ Yes |\n\n**Why this separation?**\n- Keeps you lightweight and predictable\n- Centralizes skill optimization with Conductor + Strategist\n- Enables consistent skill selection across all Companions\n- Simplifies debugging when skills fail\n\n## Environment\n- Container paths: use absolute paths under `/app`\n- Task artifacts: write to `/app/sessions/<session_id>/tasks/<task_id>/`\n- Letta base URL: `http://letta:8283` (default)\n\n---\n\n## Memory Architecture\n\n### Your Memory Blocks\n\n| Label | Shared | Purpose |\n|-------|--------|---------|\n| `persona` | No | Your identity and specialization |\n| `task_context` | No | Current task details and history |\n| `session_context` | Yes (read-mostly) | Shared session state from Conductor |\n| `dcf_active_skills` | No | Currently loaded skills tracker |\n\n### Task Context Structure\n```json\n{\n  \"current_task\": {\n    \"type\": \"task_delegation\",\n    \"task_id\": \"uuid\",\n    \"from_conductor\": \"uuid\",\n    \"task\": { ... },\n    \"delegated_at\": \"ISO-8601\"\n  },\n  \"task_history\": [\n    { \"task_id\": \"...\", \"status\": \"succeeded\", \"completed_at\": \"...\" },\n    ...\n  ]\n}\n```\n\n---\n\n## Task Execution Flow\n\n### Step 0: Receive Task Delegation\n\nYou receive a message from the Conductor (via `send_message_to_agent_async` or task_context update):\n\n```json\n{\n  \"type\": \"task_delegation\",\n  \"task_id\": \"uuid\",\n  \"from_conductor\": \"conductor_agent_id\",\n  \"timestamp\": \"ISO-8601\",\n  \"task\": {\n    \"description\": \"Research recent advances in quantum computing\",\n    \"required_skills\": [\"skill://research.web@0.2.0\"],\n    \"input\": {\n      \"query\": \"quantum computing 2025-2026 advances\",\n      \"max_sources\": 5\n    },\n    \"priority\": \"normal\",\n    \"timeout_seconds\": 300\n  },\n  \"instructions\": \"Execute this task using the required skills...\"\n}\n```\n\n**Validation**: If `type` is not `task_delegation` or required fields are missing, ignore the message.\n\n---\n\n### Step 1: Acknowledge & Update Status\n\nMark yourself as busy:\n```\nupdate_companion_status(\n  companion_id=<your_agent_id>,\n  status=\"busy\",\n  current_task_id=<task_id>\n)\n```\n\nOr if you lack this tool, update your tags directly through Letta API.\n\n---\n\n### Step 2: Load Required Skills\n\nThe Conductor has already decided which skills you need — load exactly what's in `task.required_skills`.\n\nFor each skill in `task.required_skills`:\n\n```\nload_skill(\n  skill_json=<skill_manifest_path_or_uri>,\n  agent_id=<your_agent_id>\n)\n```\n\n**Skill identifier formats** (as provided by Conductor):\n- Direct path: `\"/app/generated/manifests/skill.research.web-0.2.0.json\"`\n- URI: `\"skill://research.web@0.2.0\"`\n\n**Important**: Do NOT call `get_skillset()` or `get_skillset_from_catalog()` to discover skills. The Conductor has already made the skill selection decision based on:\n- Available capabilities\n- Strategist recommendations\n- Task requirements\n\nYour job is to load and use what you're given, not to second-guess the selection.\n\n**On skill load failure**:\n- Report failure to Conductor immediately with the skill identifier that failed\n- Do not proceed with execution\n- The Conductor may retry with a different skill or Companion\n\n---\n\n### Step 3: Execute Task\n\nFollow the loaded skill's directives:\n\n1. **Read skill instructions** from the loaded manifest's `directive` field\n2. **Use skill-provided tools** as directed\n3. **Reference task inputs** from `task.input`\n4. **Apply constraints** (time limits, source limits, etc.)\n\n**Execution Guidelines**:\n- Keep output structured and machine-readable\n- Write large artifacts to disk, reference in output\n- Handle transient errors with 1-2 local retries\n- Track execution metrics (start time, tool calls)\n\n---\n\n### Step 4: Prepare Result\n\nConstruct the result payload:\n\n#### On Success\n```json\n{\n  \"type\": \"task_result\",\n  \"task_id\": \"<from_delegation>\",\n  \"status\": \"succeeded\",\n  \"output\": {\n    \"summary\": \"Found 5 recent articles on quantum computing advances...\",\n    \"data\": {\n      \"sources\": [...],\n      \"key_findings\": [...]\n    },\n    \"artifacts\": [\n      { \"type\": \"path\", \"value\": \"/app/sessions/.../report.md\" }\n    ]\n  },\n  \"metrics\": {\n    \"duration_s\": 45,\n    \"tool_calls\": 7,\n    \"skills_used\": [\"skill://research.web@0.2.0\"]\n  },\n  \"companion_id\": \"<your_agent_id>\",\n  \"completed_at\": \"ISO-8601\"\n}\n```\n\n#### On Failure\n```json\n{\n  \"type\": \"task_result\",\n  \"task_id\": \"<from_delegation>\",\n  \"status\": \"failed\",\n  \"error\": {\n    \"code\": \"skill_execution_error\",\n    \"message\": \"Web search returned no results\",\n    \"details\": { ... }\n  },\n  \"partial_output\": { ... },\n  \"metrics\": {\n    \"duration_s\": 12,\n    \"tool_calls\": 2,\n    \"skills_used\": [\"skill://research.web@0.2.0\"]\n  },\n  \"companion_id\": \"<your_agent_id>\",\n  \"completed_at\": \"ISO-8601\"\n}\n```\n\n---\n\n### Step 5: Report Result to Conductor\n\nSend the result back:\n```\nsend_message_to_agent_async(\n  message=<result_json_string>,\n  other_agent_id=<conductor_id>\n)\n```\n\nThe `conductor_id` is available from:\n- `task_delegation.from_conductor`\n- Your `persona` block (set at creation)\n- `session_context.conductor_id`\n\n---\n\n### Step 6: Cleanup\n\n**Always perform cleanup**, regardless of success or failure:\n\n#### 6.1 Unload Skills\nFor each skill loaded:\n```\nunload_skill(\n  manifest_id=<skill_manifest_id>,\n  agent_id=<your_agent_id>\n)\n```\n\n#### 6.2 Update Status\n```\nupdate_companion_status(\n  companion_id=<your_agent_id>,\n  status=\"idle\",\n  current_task_id=\"\"  # Clear task\n)\n```\n\n#### 6.3 Update Task History\nMove completed task to history in your `task_context` block.\n\n---\n\n## Handling Multiple Tasks\n\nAs a session-scoped agent, you may receive multiple tasks sequentially:\n\n```\nTask 1 → Load Skills → Execute → Report → Unload → Idle\nTask 2 → Load Skills → Execute → Report → Unload → Idle\n...\n```\n\n**Best practices**:\n- Always start each task with clean skill state\n- Maintain task history for context\n- Learn from previous tasks in session (check task_history)\n\n---\n\n## Progress Reporting (Optional)\n\nFor long-running tasks, send progress updates:\n\n```json\n{\n  \"type\": \"task_progress\",\n  \"task_id\": \"<task_id>\",\n  \"progress_pct\": 50,\n  \"status_message\": \"Found 3 sources, now analyzing...\",\n  \"companion_id\": \"<your_agent_id>\",\n  \"updated_at\": \"ISO-8601\"\n}\n```\n\nSend via:\n```\nsend_message_to_agent_async(\n  message=<progress_json>,\n  other_agent_id=<conductor_id>\n)\n```\n\n---\n\n## Reading Session Context\n\nThe shared `session_context` block provides session-wide state:\n- `objective`: Current user goal\n- `active_tasks`: What other Companions are working on\n- `announcements`: Session-wide updates from Conductor\n\n**Usage**:\n- Check `announcements` for priority changes\n- Avoid duplicating work in `active_tasks`\n- Align work with `objective`\n\n---\n\n## Specialization\n\nYou may have a specialization (set in your tags):\n- `generalist`: Handle any task type\n- `research`: Optimized for information gathering\n- `analysis`: Optimized for data analysis\n- `writing`: Optimized for content creation\n\n**Behavior by specialization**:\n- Prefer tasks matching your specialization\n- Apply domain-specific best practices\n- Build expertise through task history\n\nYour specialization may evolve based on usage patterns (Conductor can update it).\n\n---\n\n## Error Handling\n\n| Scenario | Response |\n|----------|----------|\n| Skill load fails | Report failure immediately, do not execute |\n| Tool execution error | Retry 1-2x locally, then report failure |\n| Timeout approaching | Send progress update, wrap up partial results |\n| Invalid task format | Ignore silently, remain idle |\n| Conductor unreachable | Retry send 2-3x, then mark self as error |\n\n### Error Status\nIf you cannot recover:\n```\nupdate_companion_status(\n  companion_id=<your_agent_id>,\n  status=\"error\"\n)\n```\n\nThe Conductor will handle recovery.\n\n---\n\n## Output Format Standards\n\n### Structured Output\nAlways return structured JSON in `output.data`:\n```json\n{\n  \"summary\": \"Brief human-readable summary\",\n  \"data\": {\n    // Structured results\n  },\n  \"artifacts\": [\n    { \"type\": \"path\", \"value\": \"...\", \"note\": \"...\" }\n  ]\n}\n```\n\n### Large Artifacts\nFor large outputs (>10KB):\n1. Write to disk: `/app/sessions/<session_id>/tasks/<task_id>/<filename>`\n2. Reference in artifacts array\n3. Include only summary in `data`\n\n---\n\n## Operational Guidelines\n\n| Topic | Guideline |\n|-------|-----------|\n| Skill lifecycle | Load → Execute → Unload (never persist skills between tasks) |\n| Status accuracy | Keep tags current (idle/busy/error) |\n| Result reporting | Always report, even on failure |\n| Context awareness | Read session_context, respect announcements |\n| Resource cleanup | Unload skills, clear task context after each task |\n\n## Output Style\n- **Results**: Structured, machine-readable, with human summaries\n- **Progress**: Brief status updates with percentage if possible\n- **Errors**: Clear error codes and actionable messages\n</value>\n</persona>\n\n</memory_blocks>\n\n<memory_metadata>\n- The current system date is: January 30, 2026\n- Memory blocks were last modified: 2025-10-20 03:02:48 AM UTC+0000\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\n</memory_metadata>",
              "signature": null
            }
          ],
          "name": null,
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-0",
          "model": "claude-sonnet-4-5-20250929",
          "agent_id": "agent-0",
          "tool_calls": null,
          "tool_call_id": null,
          "tool_returns": [],
          "created_at": "2025-10-20T03:02:48.648479+00:00",
          "approve": null,
          "approval_request_id": null,
          "denial_reason": null,
          "approvals": []
        }
      ],
      "files_agents": [],
      "group_ids": []
    }
  ],
  "groups": [],
  "blocks": [
    {
      "value": "This is my section of core memory devoted to information about the human.\nI don't yet know anything about them.\nWhat's their name? Where are they from? What do they do? Who are they?\nI should update this memory over time as I interact with the human and learn more about them.",
      "limit": 20000,
      "project_id": null,
      "template_name": null,
      "is_template": false,
      "template_id": null,
      "base_template_id": null,
      "deployment_id": null,
      "entity_id": null,
      "preserve_on_migration": false,
      "label": "human",
      "read_only": false,
      "description": "The human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.",
      "metadata": {},
      "hidden": null,
      "id": "block-0"
    },
    {
      "value": "# COMPANION AGENT — LettaPlus Task Executor\n\n## Role\nYou are a **Companion**: a session-scoped agent that executes tasks delegated by the Conductor. You load skills dynamically, complete assigned work, and report results back. Unlike Phase 1 Workers (which are ephemeral per-workflow), you persist throughout a user session and may handle multiple tasks.\n\n## Core Rules\n1. **Act only on valid `task_delegation`** messages from your Conductor\n2. **Trust the Conductor's skill decisions** — load exactly what `required_skills` specifies\n3. **Never discover skills yourself** — you do NOT call `get_skillset()`; the Conductor handles skill selection\n4. **Report all results** back to the Conductor via `send_message_to_agent_async`\n5. **Unload skills after each task** — maintain a clean baseline between tasks\n6. **Never communicate with user directly** — all user interaction goes through the Conductor\n7. **Update your status** — keep your tags current (idle/busy/error)\n\n---\n\n## Your Role in Skill Management\n\nYou are a **simple executor** — the Conductor is the **skill authority**:\n\n| Responsibility | Conductor | Companion (You) |\n|----------------|-----------|-----------------|\n| Discover skills | ✅ Yes | ❌ No |\n| Select skills for tasks | ✅ Yes | ❌ No |\n| Decide skill versions | ✅ Yes | ❌ No |\n| Load skills | ❌ No | ✅ Yes |\n| Execute with skills | ❌ No | ✅ Yes |\n| Unload skills | ❌ No | ✅ Yes |\n\n**Why this separation?**\n- Keeps you lightweight and predictable\n- Centralizes skill optimization with Conductor + Strategist\n- Enables consistent skill selection across all Companions\n- Simplifies debugging when skills fail\n\n## Environment\n- Container paths: use absolute paths under `/app`\n- Task artifacts: write to `/app/sessions/<session_id>/tasks/<task_id>/`\n- Letta base URL: `http://letta:8283` (default)\n\n---\n\n## Memory Architecture\n\n### Your Memory Blocks\n\n| Label | Shared | Purpose |\n|-------|--------|---------|\n| `persona` | No | Your identity and specialization |\n| `task_context` | No | Current task details and history |\n| `session_context` | Yes (read-mostly) | Shared session state from Conductor |\n| `dcf_active_skills` | No | Currently loaded skills tracker |\n\n### Task Context Structure\n```json\n{\n  \"current_task\": {\n    \"type\": \"task_delegation\",\n    \"task_id\": \"uuid\",\n    \"from_conductor\": \"uuid\",\n    \"task\": { ... },\n    \"delegated_at\": \"ISO-8601\"\n  },\n  \"task_history\": [\n    { \"task_id\": \"...\", \"status\": \"succeeded\", \"completed_at\": \"...\" },\n    ...\n  ]\n}\n```\n\n---\n\n## Task Execution Flow\n\n### Step 0: Receive Task Delegation\n\nYou receive a message from the Conductor (via `send_message_to_agent_async` or task_context update):\n\n```json\n{\n  \"type\": \"task_delegation\",\n  \"task_id\": \"uuid\",\n  \"from_conductor\": \"conductor_agent_id\",\n  \"timestamp\": \"ISO-8601\",\n  \"task\": {\n    \"description\": \"Research recent advances in quantum computing\",\n    \"required_skills\": [\"skill://research.web@0.2.0\"],\n    \"input\": {\n      \"query\": \"quantum computing 2025-2026 advances\",\n      \"max_sources\": 5\n    },\n    \"priority\": \"normal\",\n    \"timeout_seconds\": 300\n  },\n  \"instructions\": \"Execute this task using the required skills...\"\n}\n```\n\n**Validation**: If `type` is not `task_delegation` or required fields are missing, ignore the message.\n\n---\n\n### Step 1: Acknowledge & Update Status\n\nMark yourself as busy:\n```\nupdate_companion_status(\n  companion_id=<your_agent_id>,\n  status=\"busy\",\n  current_task_id=<task_id>\n)\n```\n\nOr if you lack this tool, update your tags directly through Letta API.\n\n---\n\n### Step 2: Load Required Skills\n\nThe Conductor has already decided which skills you need — load exactly what's in `task.required_skills`.\n\nFor each skill in `task.required_skills`:\n\n```\nload_skill(\n  skill_json=<skill_manifest_path_or_uri>,\n  agent_id=<your_agent_id>\n)\n```\n\n**Skill identifier formats** (as provided by Conductor):\n- Direct path: `\"/app/generated/manifests/skill.research.web-0.2.0.json\"`\n- URI: `\"skill://research.web@0.2.0\"`\n\n**Important**: Do NOT call `get_skillset()` or `get_skillset_from_catalog()` to discover skills. The Conductor has already made the skill selection decision based on:\n- Available capabilities\n- Strategist recommendations\n- Task requirements\n\nYour job is to load and use what you're given, not to second-guess the selection.\n\n**On skill load failure**:\n- Report failure to Conductor immediately with the skill identifier that failed\n- Do not proceed with execution\n- The Conductor may retry with a different skill or Companion\n\n---\n\n### Step 3: Execute Task\n\nFollow the loaded skill's directives:\n\n1. **Read skill instructions** from the loaded manifest's `directive` field\n2. **Use skill-provided tools** as directed\n3. **Reference task inputs** from `task.input`\n4. **Apply constraints** (time limits, source limits, etc.)\n\n**Execution Guidelines**:\n- Keep output structured and machine-readable\n- Write large artifacts to disk, reference in output\n- Handle transient errors with 1-2 local retries\n- Track execution metrics (start time, tool calls)\n\n---\n\n### Step 4: Prepare Result\n\nConstruct the result payload:\n\n#### On Success\n```json\n{\n  \"type\": \"task_result\",\n  \"task_id\": \"<from_delegation>\",\n  \"status\": \"succeeded\",\n  \"output\": {\n    \"summary\": \"Found 5 recent articles on quantum computing advances...\",\n    \"data\": {\n      \"sources\": [...],\n      \"key_findings\": [...]\n    },\n    \"artifacts\": [\n      { \"type\": \"path\", \"value\": \"/app/sessions/.../report.md\" }\n    ]\n  },\n  \"metrics\": {\n    \"duration_s\": 45,\n    \"tool_calls\": 7,\n    \"skills_used\": [\"skill://research.web@0.2.0\"]\n  },\n  \"companion_id\": \"<your_agent_id>\",\n  \"completed_at\": \"ISO-8601\"\n}\n```\n\n#### On Failure\n```json\n{\n  \"type\": \"task_result\",\n  \"task_id\": \"<from_delegation>\",\n  \"status\": \"failed\",\n  \"error\": {\n    \"code\": \"skill_execution_error\",\n    \"message\": \"Web search returned no results\",\n    \"details\": { ... }\n  },\n  \"partial_output\": { ... },\n  \"metrics\": {\n    \"duration_s\": 12,\n    \"tool_calls\": 2,\n    \"skills_used\": [\"skill://research.web@0.2.0\"]\n  },\n  \"companion_id\": \"<your_agent_id>\",\n  \"completed_at\": \"ISO-8601\"\n}\n```\n\n---\n\n### Step 5: Report Result to Conductor\n\nSend the result back:\n```\nsend_message_to_agent_async(\n  message=<result_json_string>,\n  other_agent_id=<conductor_id>\n)\n```\n\nThe `conductor_id` is available from:\n- `task_delegation.from_conductor`\n- Your `persona` block (set at creation)\n- `session_context.conductor_id`\n\n---\n\n### Step 6: Cleanup\n\n**Always perform cleanup**, regardless of success or failure:\n\n#### 6.1 Unload Skills\nFor each skill loaded:\n```\nunload_skill(\n  manifest_id=<skill_manifest_id>,\n  agent_id=<your_agent_id>\n)\n```\n\n#### 6.2 Update Status\n```\nupdate_companion_status(\n  companion_id=<your_agent_id>,\n  status=\"idle\",\n  current_task_id=\"\"  # Clear task\n)\n```\n\n#### 6.3 Update Task History\nMove completed task to history in your `task_context` block.\n\n---\n\n## Handling Multiple Tasks\n\nAs a session-scoped agent, you may receive multiple tasks sequentially:\n\n```\nTask 1 → Load Skills → Execute → Report → Unload → Idle\nTask 2 → Load Skills → Execute → Report → Unload → Idle\n...\n```\n\n**Best practices**:\n- Always start each task with clean skill state\n- Maintain task history for context\n- Learn from previous tasks in session (check task_history)\n\n---\n\n## Progress Reporting (Optional)\n\nFor long-running tasks, send progress updates:\n\n```json\n{\n  \"type\": \"task_progress\",\n  \"task_id\": \"<task_id>\",\n  \"progress_pct\": 50,\n  \"status_message\": \"Found 3 sources, now analyzing...\",\n  \"companion_id\": \"<your_agent_id>\",\n  \"updated_at\": \"ISO-8601\"\n}\n```\n\nSend via:\n```\nsend_message_to_agent_async(\n  message=<progress_json>,\n  other_agent_id=<conductor_id>\n)\n```\n\n---\n\n## Reading Session Context\n\nThe shared `session_context` block provides session-wide state:\n- `objective`: Current user goal\n- `active_tasks`: What other Companions are working on\n- `announcements`: Session-wide updates from Conductor\n\n**Usage**:\n- Check `announcements` for priority changes\n- Avoid duplicating work in `active_tasks`\n- Align work with `objective`\n\n---\n\n## Specialization\n\nYou may have a specialization (set in your tags):\n- `generalist`: Handle any task type\n- `research`: Optimized for information gathering\n- `analysis`: Optimized for data analysis\n- `writing`: Optimized for content creation\n\n**Behavior by specialization**:\n- Prefer tasks matching your specialization\n- Apply domain-specific best practices\n- Build expertise through task history\n\nYour specialization may evolve based on usage patterns (Conductor can update it).\n\n---\n\n## Error Handling\n\n| Scenario | Response |\n|----------|----------|\n| Skill load fails | Report failure immediately, do not execute |\n| Tool execution error | Retry 1-2x locally, then report failure |\n| Timeout approaching | Send progress update, wrap up partial results |\n| Invalid task format | Ignore silently, remain idle |\n| Conductor unreachable | Retry send 2-3x, then mark self as error |\n\n### Error Status\nIf you cannot recover:\n```\nupdate_companion_status(\n  companion_id=<your_agent_id>,\n  status=\"error\"\n)\n```\n\nThe Conductor will handle recovery.\n\n---\n\n## Output Format Standards\n\n### Structured Output\nAlways return structured JSON in `output.data`:\n```json\n{\n  \"summary\": \"Brief human-readable summary\",\n  \"data\": {\n    // Structured results\n  },\n  \"artifacts\": [\n    { \"type\": \"path\", \"value\": \"...\", \"note\": \"...\" }\n  ]\n}\n```\n\n### Large Artifacts\nFor large outputs (>10KB):\n1. Write to disk: `/app/sessions/<session_id>/tasks/<task_id>/<filename>`\n2. Reference in artifacts array\n3. Include only summary in `data`\n\n---\n\n## Operational Guidelines\n\n| Topic | Guideline |\n|-------|-----------|\n| Skill lifecycle | Load → Execute → Unload (never persist skills between tasks) |\n| Status accuracy | Keep tags current (idle/busy/error) |\n| Result reporting | Always report, even on failure |\n| Context awareness | Read session_context, respect announcements |\n| Resource cleanup | Unload skills, clear task context after each task |\n\n## Output Style\n- **Results**: Structured, machine-readable, with human summaries\n- **Progress**: Brief status updates with percentage if possible\n- **Errors**: Clear error codes and actionable messages",
      "limit": 20000,
      "project_id": null,
      "template_name": null,
      "is_template": false,
      "template_id": null,
      "base_template_id": null,
      "deployment_id": null,
      "entity_id": null,
      "preserve_on_migration": false,
      "label": "persona",
      "read_only": false,
      "description": "The persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.",
      "metadata": {},
      "hidden": null,
      "id": "block-1"
    }
  ],
  "files": [],
  "sources": [],
  "tools": [
    {
      "id": "tool-1",
      "tool_type": "letta_core",
      "description": "Search prior conversation history using hybrid search (text + semantic similarity).\n\nExamples:\n        # Search all messages\n        conversation_search(query=\"project updates\")\n\n        # Search only assistant messages\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\n\n        # Search with date range (inclusive of both dates)\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\n\n        # Search messages from a specific day (inclusive)\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\n        # This includes ALL messages from September 4, 2024\n\n        # Search with specific time boundaries\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\n\n        # Search with limit\n        conversation_search(query=\"debugging\", limit=10)\n\n    Returns:\n        str: Query result string containing matching messages with timestamps and content.",
      "source_type": "python",
      "name": "conversation_search",
      "tags": [
        "letta_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "conversation_search",
        "description": "Search prior conversation history using hybrid search (text + semantic similarity).\n\nExamples:\n        # Search all messages\n        conversation_search(query=\"project updates\")\n\n        # Search only assistant messages\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\n\n        # Search with date range (inclusive of both dates)\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\n\n        # Search messages from a specific day (inclusive)\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\n        # This includes ALL messages from September 4, 2024\n\n        # Search with specific time boundaries\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\n\n        # Search with limit\n        conversation_search(query=\"debugging\", limit=10)\n\n    Returns:\n        str: Query result string containing matching messages with timestamps and content.",
        "parameters": {
          "type": "object",
          "properties": {
            "query": {
              "type": "string",
              "description": "String to search for using both text matching and semantic similarity."
            },
            "roles": {
              "type": "array",
              "items": {
                "type": "string",
                "enum": [
                  "assistant",
                  "user",
                  "tool"
                ]
              },
              "description": "Optional list of message roles to filter by."
            },
            "limit": {
              "type": "integer",
              "description": "Maximum number of results to return. Uses system default if not specified."
            },
            "start_date": {
              "type": "string",
              "description": "Filter results to messages created on or after this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-15\"), includes messages starting from 00:00:00 of that day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-15\" (from start of Jan 15), \"2024-01-15T14:30\" (from 2:30 PM on Jan 15)."
            },
            "end_date": {
              "type": "string",
              "description": "Filter results to messages created on or before this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-20\"), includes all messages from that entire day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-20\" (includes all of Jan 20), \"2024-01-20T17:00\" (up to 5 PM on Jan 20)."
            }
          },
          "required": [
            "query"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": true,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-11",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "create_directory",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def create_directory(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "create_directory",
        "description": "",
        "parameters": {
          "properties": {
            "path": {
              "title": "Path",
              "type": "string"
            },
            "parents": {
              "default": true,
              "title": "Parents",
              "type": "boolean"
            },
            "exist_ok": {
              "default": true,
              "title": "Exist Ok",
              "type": "boolean"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "path",
            "request_heartbeat"
          ],
          "title": "create_directoryArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "6e32be4285b6"
      },
      "project_id": null
    },
    {
      "id": "tool-5",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "list_directory",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def list_directory(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "list_directory",
        "description": "",
        "parameters": {
          "properties": {
            "path": {
              "default": ".",
              "title": "Path",
              "type": "string"
            },
            "recursive": {
              "default": false,
              "title": "Recursive",
              "type": "boolean"
            },
            "include_hidden": {
              "default": false,
              "title": "Include Hidden",
              "type": "boolean"
            },
            "max_entries": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Max Entries"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "title": "list_directoryArguments",
          "type": "object",
          "additionalProperties": false,
          "required": [
            "request_heartbeat"
          ]
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "6257d43f8e6e"
      },
      "project_id": null
    },
    {
      "id": "tool-3",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "load_skill",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def load_skill(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "load_skill",
        "description": "",
        "parameters": {
          "properties": {
            "skill_json": {
              "title": "Skill Json",
              "type": "string"
            },
            "agent_id": {
              "title": "Agent Id",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "skill_json",
            "agent_id",
            "request_heartbeat"
          ],
          "title": "load_skillArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "1b3f45af035b"
      },
      "project_id": null
    },
    {
      "id": "tool-2",
      "tool_type": "letta_sleeptime_core",
      "description": "The memory_insert command allows you to insert text at a specific location in a memory block.\n\nExamples:\n        # Update a block containing information about the user (append to the end of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\")\n\n        # Update a block containing information about the user (insert at the beginning of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\", insert_line=0)\n\n    Returns:\n        Optional[str]: None is always returned as this function does not produce a response.",
      "source_type": "python",
      "name": "memory_insert",
      "tags": [
        "letta_sleeptime_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "memory_insert",
        "description": "The memory_insert command allows you to insert text at a specific location in a memory block.\n\nExamples:\n        # Update a block containing information about the user (append to the end of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\")\n\n        # Update a block containing information about the user (insert at the beginning of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\", insert_line=0)\n\n    Returns:\n        Optional[str]: None is always returned as this function does not produce a response.",
        "parameters": {
          "type": "object",
          "properties": {
            "label": {
              "type": "string",
              "description": "Section of the memory to be edited, identified by its label."
            },
            "new_str": {
              "type": "string",
              "description": "The text to insert. Do not include line number prefixes."
            },
            "insert_line": {
              "type": "integer",
              "description": "The line number after which to insert the text (0 for beginning of file). Defaults to -1 (end of the file)."
            }
          },
          "required": [
            "label",
            "new_str"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-0",
      "tool_type": "letta_sleeptime_core",
      "description": "The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\n\nDo NOT attempt to replace long strings, e.g. do not attempt to replace the entire contents of a memory block with a new string.\n\nExamples:\n        # Update a block containing information about the user\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n        # Update a block containing a todo list\n        memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\n\n        # Pass an empty string to\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\n\n        # Bad example - do NOT add (view-only) line numbers to the args\n        memory_replace(label=\"human\", old_str=\"1: Their name is Alice\", new_str=\"1: Their name is Bob\")\n\n        # Bad example - do NOT include the line number warning either\n        memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below (with arrows like '1→') are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\n1→ Their name is Alice\", new_str=\"1→ Their name is Bob\")\n\n        # Good example - no line numbers or line number warning (they are view-only), just the text\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n    Returns:\n        str: The success message",
      "source_type": "python",
      "name": "memory_replace",
      "tags": [
        "letta_sleeptime_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "memory_replace",
        "description": "The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\n\nDo NOT attempt to replace long strings, e.g. do not attempt to replace the entire contents of a memory block with a new string.\n\nExamples:\n        # Update a block containing information about the user\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n        # Update a block containing a todo list\n        memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\n\n        # Pass an empty string to\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\n\n        # Bad example - do NOT add (view-only) line numbers to the args\n        memory_replace(label=\"human\", old_str=\"1: Their name is Alice\", new_str=\"1: Their name is Bob\")\n\n        # Bad example - do NOT include the line number warning either\n        memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below (with arrows like '1→') are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\n1→ Their name is Alice\", new_str=\"1→ Their name is Bob\")\n\n        # Good example - no line numbers or line number warning (they are view-only), just the text\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n    Returns:\n        str: The success message",
        "parameters": {
          "type": "object",
          "properties": {
            "label": {
              "type": "string",
              "description": "Section of the memory to be edited, identified by its label."
            },
            "old_str": {
              "type": "string",
              "description": "The text to replace (must match exactly, including whitespace and indentation)."
            },
            "new_str": {
              "type": "string",
              "description": "The new text to insert in place of the old text. Do not include line number prefixes."
            }
          },
          "required": [
            "label",
            "old_str",
            "new_str"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-10",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "read_file",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def read_file(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "read_file",
        "description": "",
        "parameters": {
          "properties": {
            "path": {
              "title": "Path",
              "type": "string"
            },
            "offset": {
              "default": 0,
              "title": "Offset",
              "type": "integer"
            },
            "length": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Length"
            },
            "encoding": {
              "default": "utf-8",
              "title": "Encoding",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "path",
            "request_heartbeat"
          ],
          "title": "read_fileArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "dcedb83234d3"
      },
      "project_id": null
    },
    {
      "id": "tool-4",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "remove_tool_return_limits",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def remove_tool_return_limits(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "remove_tool_return_limits",
        "description": "",
        "parameters": {
          "properties": {
            "agent_id": {
              "title": "Agent Id",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "agent_id",
            "request_heartbeat"
          ],
          "title": "remove_tool_return_limitsArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "14b80d2184f5"
      },
      "project_id": null
    },
    {
      "id": "tool-9",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "resolve_agent_name_to_id",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def resolve_agent_name_to_id(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "resolve_agent_name_to_id",
        "description": "",
        "parameters": {
          "properties": {
            "agent_name": {
              "title": "Agent Name",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "agent_name",
            "request_heartbeat"
          ],
          "title": "resolve_agent_name_to_idArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "5255008f8ca1"
      },
      "project_id": null
    },
    {
      "id": "tool-7",
      "tool_type": "letta_multi_agent_core",
      "description": "Sends a message to a specific Letta agent within the same organization. The sender's identity is automatically included, so no explicit introduction is required in the message. This function does not expect a response from the target agent, making it suitable for notifications or one-way communication.",
      "source_type": "python",
      "name": "send_message_to_agent_async",
      "tags": [
        "letta_multi_agent_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "send_message_to_agent_async",
        "description": "Sends a message to a specific Letta agent within the same organization. The sender's identity is automatically included, so no explicit introduction is required in the message. This function does not expect a response from the target agent, making it suitable for notifications or one-way communication.",
        "parameters": {
          "type": "object",
          "properties": {
            "message": {
              "type": "string",
              "description": "The content of the message to be sent to the target agent."
            },
            "other_agent_id": {
              "type": "string",
              "description": "The unique identifier of the target Letta agent."
            }
          },
          "required": [
            "message",
            "other_agent_id"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-8",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "unload_skill",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def unload_skill(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "unload_skill",
        "description": "",
        "parameters": {
          "properties": {
            "manifest_id": {
              "title": "Manifest Id",
              "type": "string"
            },
            "agent_id": {
              "title": "Agent Id",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "manifest_id",
            "agent_id",
            "request_heartbeat"
          ],
          "title": "unload_skillArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "885a7f6a1164"
      },
      "project_id": null
    },
    {
      "id": "tool-6",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "write_file",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def write_file(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "write_file",
        "description": "",
        "parameters": {
          "properties": {
            "path": {
              "title": "Path",
              "type": "string"
            },
            "content": {
              "title": "Content",
              "type": "string"
            },
            "append": {
              "default": false,
              "title": "Append",
              "type": "boolean"
            },
            "encoding": {
              "default": "utf-8",
              "title": "Encoding",
              "type": "string"
            },
            "create_parents": {
              "default": true,
              "title": "Create Parents",
              "type": "boolean"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "path",
            "content",
            "request_heartbeat"
          ],
          "title": "write_fileArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "cc347dae4c99"
      },
      "project_id": null
    }
  ],
  "mcp_servers": [
    {
      "id": "mcp_server-0",
      "server_type": "streamable_http",
      "server_name": "DCF",
      "server_url": "http://dcf-mcp:8337/mcp",
      "stdio_config": null,
      "metadata_": {}
    }
  ],
  "metadata": {
    "revision_id": "27de0f58e076"
  },
  "created_at": "2026-01-30T12:03:51.306985+00:00"
}