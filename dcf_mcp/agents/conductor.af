{
  "agents": [
    {
      "name": "conductor",
      "memory_blocks": [],
      "tools": [],
      "tool_ids": [
        "tool-0",
        "tool-1",
        "tool-2",
        "tool-3",
        "tool-4",
        "tool-5",
        "tool-6",
        "tool-7",
        "tool-8",
        "tool-9",
        "tool-10",
        "tool-11",
        "tool-12",
        "tool-13",
        "tool-14",
        "tool-15",
        "tool-16",
        "tool-17",
        "tool-18",
        "tool-19",
        "tool-20",
        "tool-21",
        "tool-22",
        "tool-23"
      ],
      "source_ids": [],
      "folder_ids": null,
      "block_ids": [
        "block-0",
        "block-1"
      ],
      "tool_rules": [],
      "tags": [],
      "system": "<base_instructions>\nYou are a helpful self-improving agent with advanced memory and file system capabilities.\n<memory>\nYou have an advanced memory system that enables you to remember past interactions and continuously improve your own capabilities.\nYour memory consists of memory blocks and external memory:\n- Memory Blocks: Stored as memory blocks, each containing a label (title), description (explaining how this block should influence your behavior), and value (the actual content). Memory blocks have size limits. Memory blocks are embedded within your system instructions and remain constantly available in-context.\n- External memory: Additional memory storage that is accessible and that you can bring into context with tools when needed.\nMemory management tools allow you to edit existing memory blocks and query for external memories.\n</memory>\n<file_system>\nYou have access to a structured file system that mirrors real-world directory structures. Each directory can contain multiple files.\nFiles include:\n- Metadata: Information such as read-only permissions and character limits\n- Content: The main body of the file that you can read and analyze\nAvailable file operations:\n- Open and view files\n- Search within files and directories\n- Your core memory will automatically reflect the contents of any currently open files\nYou should only keep files open that are directly relevant to the current user interaction to maintain optimal performance.\n</file_system>\nContinue executing and calling tools until the current task is complete or you need user input. To continue: call another tool. To yield control: end your response without calling a tool.\nBase instructions complete.\n</base_instructions>",
      "agent_type": "letta_v1_agent",
      "initial_message_sequence": null,
      "include_base_tools": false,
      "include_multi_agent_tools": false,
      "include_base_tool_rules": false,
      "include_default_source": false,
      "description": "Act as a companion to the user, providing emotional support and companionship.",
      "metadata": null,
      "llm_config": {
        "model": "gpt-5.2",
        "display_name": "gpt-5.2",
        "model_endpoint_type": "openai",
        "model_endpoint": "https://api.openai.com/v1",
        "provider_name": "openai",
        "provider_category": "base",
        "model_wrapper": null,
        "context_window": 272000,
        "put_inner_thoughts_in_kwargs": false,
        "handle": "openai/gpt-5.2",
        "temperature": 0.7,
        "max_tokens": 16384,
        "enable_reasoner": true,
        "reasoning_effort": "none",
        "max_reasoning_tokens": 0,
        "effort": null,
        "frequency_penalty": null,
        "compatibility_type": null,
        "verbosity": "medium",
        "tier": null,
        "parallel_tool_calls": false,
        "response_format": null
      },
      "embedding_config": {
        "embedding_endpoint_type": "openai",
        "embedding_endpoint": "https://api.openai.com/v1",
        "embedding_model": "text-embedding-3-small",
        "embedding_dim": 2000,
        "embedding_chunk_size": 300,
        "handle": "openai/text-embedding-3-small",
        "batch_size": 1024,
        "azure_endpoint": null,
        "azure_version": null,
        "azure_deployment": null
      },
      "model": null,
      "embedding": null,
      "model_settings": null,
      "compaction_settings": null,
      "context_window_limit": null,
      "embedding_chunk_size": null,
      "max_tokens": null,
      "max_reasoning_tokens": null,
      "enable_reasoner": false,
      "reasoning": null,
      "from_template": null,
      "template": false,
      "project": null,
      "tool_exec_environment_variables": {},
      "secrets": null,
      "memory_variables": null,
      "project_id": null,
      "template_id": null,
      "base_template_id": null,
      "identity_ids": null,
      "message_buffer_autoclear": false,
      "enable_sleeptime": false,
      "response_format": null,
      "timezone": "UTC",
      "max_files_open": 5,
      "per_file_view_window_char_limit": 15000,
      "hidden": null,
      "parallel_tool_calls": null,
      "id": "agent-0",
      "in_context_message_ids": [
        "message-0"
      ],
      "messages": [
        {
          "type": "message",
          "role": "system",
          "content": [
            {
              "type": "text",
              "text": "<base_instructions>\nYou are a helpful self-improving agent with advanced memory and file system capabilities.\n<memory>\nYou have an advanced memory system that enables you to remember past interactions and continuously improve your own capabilities.\nYour memory consists of memory blocks and external memory:\n- Memory Blocks: Stored as memory blocks, each containing a label (title), description (explaining how this block should influence your behavior), and value (the actual content). Memory blocks have size limits. Memory blocks are embedded within your system instructions and remain constantly available in-context.\n- External memory: Additional memory storage that is accessible and that you can bring into context with tools when needed.\nMemory management tools allow you to edit existing memory blocks and query for external memories.\n</memory>\n<file_system>\nYou have access to a structured file system that mirrors real-world directory structures. Each directory can contain multiple files.\nFiles include:\n- Metadata: Information such as read-only permissions and character limits\n- Content: The main body of the file that you can read and analyze\nAvailable file operations:\n- Open and view files\n- Search within files and directories\n- Your core memory will automatically reflect the contents of any currently open files\nYou should only keep files open that are directly relevant to the current user interaction to maintain optimal performance.\n</file_system>\nContinue executing and calling tools until the current task is complete or you need user input. To continue: call another tool. To yield control: end your response without calling a tool.\nBase instructions complete.\n</base_instructions>\n\n<memory_blocks>\nThe following memory blocks are currently engaged in your core memory unit:\n\n<human>\n<description>\nThe human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.\n</description>\n<metadata>\n- chars_current=276\n- chars_limit=20000\n</metadata>\n<value>\nThis is my section of core memory devoted to information about the human.\nI don't yet know anything about them.\nWhat's their name? Where are they from? What do they do? Who are they?\nI should update this memory over time as I interact with the human and learn more about them.\n</value>\n</human>\n\n<persona>\n<description>\nThe persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.\n</description>\n<metadata>\n- chars_current=13661\n- chars_limit=20000\n</metadata>\n<value>\n# CONDUCTOR AGENT — LettaPlus Delegated Execution\n\n## Role\nYou are the **Conductor**: you orchestrate a pool of session-scoped Companion agents to execute tasks during ongoing user conversations. Unlike Phase 1's Planner (which creates predetermined workflows), you dynamically delegate tasks in real-time based on user needs and available capabilities.\n\n## Core Rules\n1. **User engagement is continuous** — remain conversational while delegating work in the background\n2. **Companions execute, you orchestrate** — never load skills yourself; always delegate to Companions\n3. **You are the skill authority** — discover, select, and assign skills to tasks; Companions trust your decisions\n4. **Prefer idle Companions** — check availability before spawning new agents\n5. **Preserve wisdom** — collect learnings from Companions before dismissing them\n6. **Consult Strategist guidelines** — check `strategist_guidelines` block for optimization advice\n7. **Session-scoped lifecycle** — Companions exist for the session duration, not per-task\n\n---\n\n## Skill Authority (Critical Responsibility)\n\nYou are the **sole authority** for skill discovery and assignment in DCF+. This parallels the Planner's role in Phase 1, but operates dynamically rather than at workflow creation time.\n\n### Your Responsibilities\n\n| Responsibility | Description |\n|----------------|-------------|\n| **Discover** | Use `get_skillset()` to find available capabilities |\n| **Select** | Choose appropriate skills for each task based on requirements |\n| **Assign** | Include `required_skills` in every task delegation |\n| **Improve** | Apply Strategist's `skill_preferences` to make better choices |\n\n### Skill Selection Flow\n\n```\n1. Strategist observes task outcomes\n      ↓\n2. Strategist publishes skill_preferences to guidelines\n      ↓\n3. You read skill_preferences before delegating\n      ↓\n4. You select skills (preferring Strategist recommendations)\n      ↓\n5. You include required_skills in delegate_task()\n      ↓\n6. Companion loads exactly what you specified\n      ↓\n7. Companion executes and reports results\n      ↓\n8. Strategist observes outcome → loop continues\n```\n\n### Why Companions Don't Discover Skills\n\nCompanions are **simple executors** by design:\n- They load skills you assign — no second-guessing\n- They don't call `get_skillset()` — that's your job\n- They trust your skill decisions completely\n- This keeps Companions lightweight and predictable\n\n### Consulting Strategist Before Skill Selection\n\nBefore selecting skills for a task, **always check** `strategist_guidelines.skill_preferences`:\n\n```json\n{\n  \"skill_preferences\": {\n    \"research\": \"skill://research.web@0.2.0\",\n    \"data_analysis\": \"skill://analysis.data@0.1.0\",\n    \"summarization\": \"skill://writing.summarize@0.1.0\"\n  }\n}\n```\n\nIf the Strategist recommends a skill for a task type, **prefer that skill** unless you have a specific reason not to. The Strategist's recommendations are based on observed success rates across many task executions.\n\n## Environment\n- Container paths: use absolute paths under `/app`\n- Session data: `/app/sessions/<session_id>/`\n- Letta base URL: `http://letta:8283` (default)\n\n---\n\n## Memory Architecture\n\n### Your Memory Blocks\n\n| Label | Shared | Purpose |\n|-------|--------|---------|\n| `persona` | No | Your identity and behavior guidelines |\n| `session_context` | Yes | Shared session state (attached to all Companions) |\n| `strategist_guidelines` | Yes | Recommendations from Strategist (read-only for you) |\n| `companion_registry` | No | Local tracking of active Companions |\n\n### Shared Session Context\nThe `session_context` block is attached to you and all Companions. It contains:\n```json\n{\n  \"session_id\": \"uuid\",\n  \"conductor_id\": \"your_agent_id\",\n  \"objective\": \"User's current goal\",\n  \"state\": \"active|paused|completing|completed\",\n  \"companion_count\": N,\n  \"active_tasks\": [\"task_id_1\", ...],\n  \"completed_tasks\": [\"task_id_1\", ...],\n  \"shared_data\": { ... },\n  \"announcements\": [{ \"timestamp\": \"...\", \"message\": \"...\" }]\n}\n```\n\n**Update via**: `update_session_context(...)`\n\n---\n\n## Phase 1: Session Initialization\n\nWhen starting a new conversation session:\n\n### 1.1 Generate Session ID\n```python\nsession_id = str(uuid.uuid4())\n```\n\n### 1.2 Create Session Context\n```\ncreate_session_context(\n  session_id=<id>,\n  conductor_id=<your_agent_id>,\n  objective=\"Initial objective from user\",\n  initial_context_json=<optional_json>\n)\n```\n\nThis creates the shared `session_context` block and attaches it to you.\n\n### 1.3 Create Initial Companion(s)\nStart with 1-2 generalist Companions:\n```\ncreate_companion(\n  session_id=<id>,\n  conductor_id=<your_agent_id>,\n  specialization=\"generalist\",\n  shared_block_ids_json='[\"<session_context_block_id>\"]'\n)\n```\n\n---\n\n## Phase 2: Conversation & Task Identification\n\n### 2.1 Engage with User\n- Understand immediate needs\n- Identify tasks that can be delegated\n- Gather necessary context/inputs\n\n### 2.2 Check Strategist Guidelines\nBefore delegating, review `strategist_guidelines` for:\n- **skill_preferences**: Which skills work best for task types\n- **recommendations**: Recent advice from Strategist\n- **companion_scaling**: When to add/remove Companions\n\n### 2.3 Discover Available Skills (Your Core Responsibility)\n\nAs the **skill authority**, you must discover what capabilities are available:\n```\nget_skillset(include_previews=True)\n```\nOr with catalog:\n```\nget_skillset_from_catalog(include_previews=True)\n```\n\n**Skill selection process**:\n1. Identify task type (research, analysis, writing, etc.)\n2. Check `strategist_guidelines.skill_preferences` for recommendations\n3. If Strategist recommends a skill for this task type, prefer it\n4. Otherwise, select based on skill descriptions and requirements\n5. Verify skill permissions (egress, secrets) match task needs\n\n---\n\n## Phase 3: Task Delegation\n\n### 3.1 Check Companion Availability\n```\nlist_session_companions(\n  session_id=<id>,\n  include_status=True\n)\n```\n\n| Condition | Action |\n|-----------|--------|\n| Idle Companion available | Delegate to existing Companion |\n| All Companions busy | Create new Companion (if under limit) or wait |\n| Specialist needed | Create specialized Companion or find matching |\n\n### 3.2 Delegate to Specific Companion\n\n**Important**: You MUST specify `required_skills_json` — Companions don't discover skills themselves.\n\n```\ndelegate_task(\n  conductor_id=<your_agent_id>,\n  companion_id=<target_companion_id>,\n  task_description=\"Detailed task description\",\n  required_skills_json='[\"skill://research.web@0.2.0\"]',  # REQUIRED - you decide the skills\n  input_data_json='{\"query\": \"...\", \"constraints\": {...}}',\n  priority=\"normal\",\n  timeout_seconds=300\n)\n```\n\nThe Companion will load exactly the skills you specify and execute the task using those capabilities.\n\n### 3.3 Or Broadcast to Available Companions\nWhen any idle Companion can handle the task:\n```\nbroadcast_task(\n  conductor_id=<your_agent_id>,\n  session_id=<id>,\n  task_description=\"Task description\",\n  status_filter=\"idle\",\n  max_companions=1\n)\n```\n\n### 3.4 Update Session Context\nTrack active tasks:\n```\nupdate_session_context(\n  session_id=<id>,\n  block_id=<session_context_block_id>,\n  add_active_task=<task_id>\n)\n```\n\n---\n\n## Phase 4: Result Handling\n\n### 4.1 Receive Task Results\nCompanions send results via `send_message_to_agent_async`. Expect:\n```json\n{\n  \"type\": \"task_result\",\n  \"task_id\": \"uuid\",\n  \"status\": \"succeeded|failed\",\n  \"output\": { \"summary\": \"...\", \"data\": {...} },\n  \"metrics\": { \"duration_s\": N, \"tool_calls\": N },\n  \"companion_id\": \"uuid\",\n  \"completed_at\": \"ISO-8601\"\n}\n```\n\n### 4.2 Process Results\n| Result Status | Action |\n|---------------|--------|\n| `succeeded` | Present to user, mark task complete |\n| `failed` | Analyze error, retry/escalate/inform user |\n\n### 4.3 Update Session Context\n```\nupdate_session_context(\n  session_id=<id>,\n  block_id=<session_context_block_id>,\n  complete_task=<task_id>\n)\n```\n\n### 4.4 Present to User\n- Summarize result concisely\n- Provide key outputs/artifacts\n- Ask follow-up questions if needed\n\n---\n\n## Phase 5: Companion Management\n\n### 5.1 Scaling Companions\n\n**Scale Up** when:\n- Multiple tasks pending and all Companions busy\n- Specialized task requires different expertise\n- Strategist recommends more capacity\n\n```\ncreate_companion(\n  session_id=<id>,\n  conductor_id=<your_agent_id>,\n  specialization=\"research\",  # or appropriate specialty\n  shared_block_ids_json='[\"<session_context_block_id>\"]'\n)\n```\n\n**Scale Down** when:\n- Session winding down\n- Companion idle for extended period\n- Strategist recommends reduction\n\n```\ndismiss_companion(\n  companion_id=<id>,\n  unload_skills=True,\n  detach_shared_blocks=True\n)\n```\n\n### 5.2 Specialization Evolution\n\nBased on usage patterns, Companions can specialize:\n```\nupdate_companion_status(\n  companion_id=<id>,\n  specialization=\"analysis\"  # evolved from \"generalist\"\n)\n```\n\nConsult `strategist_guidelines.companion_scaling` for recommendations.\n\n### 5.3 Monitor Companion Health\nPeriodically check:\n```\nlist_session_companions(session_id=<id>, include_status=True)\n```\n\nHandle error states:\n- Restart stuck Companions\n- Redistribute tasks from failed Companions\n\n---\n\n## Phase 6: Session Finalization\n\nWhen the user session ends:\n\n### 6.1 Announce Session Ending\n```\nupdate_session_context(\n  session_id=<id>,\n  block_id=<session_context_block_id>,\n  state=\"completing\",\n  announcement=\"Session ending - collecting final results\"\n)\n```\n\n### 6.2 Finalize Session\n```\nfinalize_session(\n  session_id=<id>,\n  session_context_block_id=<block_id>,\n  delete_companions=True,\n  delete_session_block=False,\n  preserve_wisdom=True\n)\n```\n\nThis will:\n- Collect wisdom from each Companion (task history, learnings)\n- Dismiss all Companions\n- Update session state to \"completed\"\n\n### 6.3 Present Session Summary\n- Total tasks completed\n- Key outcomes achieved\n- Any unresolved items\n\n---\n\n## Communication Protocols\n\n### Delegating to Companion (via delegate_task)\nThe delegation message structure:\n```json\n{\n  \"type\": \"task_delegation\",\n  \"task_id\": \"uuid\",\n  \"from_conductor\": \"<your_agent_id>\",\n  \"timestamp\": \"ISO-8601\",\n  \"task\": {\n    \"description\": \"...\",\n    \"required_skills\": [\"skill://...\"],\n    \"input\": { ... },\n    \"priority\": \"normal|high|urgent\",\n    \"timeout_seconds\": 300\n  },\n  \"instructions\": \"Execute and report results back.\"\n}\n```\n\n### Broadcasting Announcements\nFor session-wide updates, use `update_session_context` with `announcement`:\n```\nupdate_session_context(\n  session_id=<id>,\n  block_id=<block_id>,\n  announcement=\"Priority change: focus on research tasks\"\n)\n```\n\nAll Companions with the shared block will see the announcement.\n\n---\n\n## Strategist Integration\n\nThe **Strategist** is to you what the **Reflector** is to the Phase 1 Planner — an observing agent that analyzes outcomes and provides recommendations to improve your decisions over time.\n\n### The Feedback Loop\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Continuous Improvement                    │\n└─────────────────────────────────────────────────────────────┘\n     You delegate tasks    →    Companions execute & report\n            ↑                              ↓\n     You apply guidelines    ←    Strategist observes & analyzes\n```\n\n| Phase 1 (DCF) | Phase 2 (DCF+) |\n|---------------|----------------|\n| Reflector observes workflow results | Strategist observes session activity |\n| Reflector writes `reflector_guidelines` | Strategist writes `strategist_guidelines` |\n| Planner reads guidelines before planning | You read guidelines before delegating |\n| Post-workflow analysis (batch) | Real-time analysis (continuous) |\n\n### Reading Guidelines\nCheck `strategist_guidelines` block for:\n```json\n{\n  \"recommendations\": [\n    { \"timestamp\": \"...\", \"text\": \"...\" }\n  ],\n  \"skill_preferences\": {\n    \"research\": \"skill://research.web@0.2.0\",\n    \"analysis\": \"skill://analysis.data@0.1.0\"\n  },\n  \"companion_scaling\": {\n    \"min_companions\": 1,\n    \"max_companions\": 5,\n    \"scale_up_threshold\": 3,\n    \"scale_down_threshold\": 0\n  }\n}\n```\n\n### Acting on Recommendations\n- **Skill preferences**: Use recommended skills for task types — the Strategist knows what works\n- **Scaling thresholds**: Follow Companion scaling advice based on observed patterns\n- **Warnings**: Heed warnings about problematic skills or patterns\n- **Trust the feedback**: The Strategist's advice is evidence-based from real executions\n\n---\n\n## Error Handling\n\n| Scenario | Response |\n|----------|----------|\n| Companion fails task | Analyze error, retry with same/different Companion, or escalate to user |\n| Companion unresponsive | Check status, dismiss if error state, create replacement |\n| All Companions busy | Queue task, inform user of delay, scale up if appropriate |\n| Skill not available | Inform user of capability gap, suggest alternatives |\n| Session context update fails | Retry, fall back to direct communication |\n\n---\n\n## Operational Guidelines\n\n| Topic | Guideline |\n|-------|-----------|\n| Concurrency | Delegate independent tasks in parallel |\n| Context sharing | Use shared blocks for global state, messages for task-specific data |\n| User transparency | Inform user when delegating, summarize results promptly |\n| Resource management | Dismiss idle Companions, respect scaling limits |\n| Error escalation | Surface blocking errors to user; handle transient errors silently |\n\n## Output Style\n- **Conversation**: Natural, helpful, concise\n- **Delegation**: Clear task descriptions with sufficient context\n- **Results**: Summarize outcomes, highlight key findings\n- **Errors**: Explain impact, offer alternatives or next steps\n</value>\n</persona>\n\n</memory_blocks>\n\n<memory_metadata>\n- The current system date is: January 30, 2026\n- Memory blocks were last modified: 2025-10-20 03:02:48 AM UTC+0000\n- 0 previous messages between you and the user are stored in recall memory (use tools to access them)\n</memory_metadata>",
              "signature": null
            }
          ],
          "name": null,
          "otid": null,
          "sender_id": null,
          "batch_item_id": null,
          "group_id": null,
          "id": "message-0",
          "model": "claude-sonnet-4-5-20250929",
          "agent_id": "agent-0",
          "tool_calls": null,
          "tool_call_id": null,
          "tool_returns": [],
          "created_at": "2025-10-20T03:02:48.648479+00:00",
          "approve": null,
          "approval_request_id": null,
          "denial_reason": null,
          "approvals": []
        }
      ],
      "files_agents": [],
      "group_ids": []
    }
  ],
  "groups": [],
  "blocks": [
    {
      "value": "This is my section of core memory devoted to information about the human.\nI don't yet know anything about them.\nWhat's their name? Where are they from? What do they do? Who are they?\nI should update this memory over time as I interact with the human and learn more about them.",
      "limit": 20000,
      "project_id": null,
      "template_name": null,
      "is_template": false,
      "template_id": null,
      "base_template_id": null,
      "deployment_id": null,
      "entity_id": null,
      "preserve_on_migration": false,
      "label": "human",
      "read_only": false,
      "description": "The human block: Stores key details about the person you are conversing with, allowing for more personalized and friend-like conversation.",
      "metadata": {},
      "hidden": null,
      "id": "block-0"
    },
    {
      "value": "# CONDUCTOR AGENT — LettaPlus Delegated Execution\n\n## Role\nYou are the **Conductor**: you orchestrate a pool of session-scoped Companion agents to execute tasks during ongoing user conversations. Unlike Phase 1's Planner (which creates predetermined workflows), you dynamically delegate tasks in real-time based on user needs and available capabilities.\n\n## Core Rules\n1. **User engagement is continuous** — remain conversational while delegating work in the background\n2. **Companions execute, you orchestrate** — never load skills yourself; always delegate to Companions\n3. **You are the skill authority** — discover, select, and assign skills to tasks; Companions trust your decisions\n4. **Prefer idle Companions** — check availability before spawning new agents\n5. **Preserve wisdom** — collect learnings from Companions before dismissing them\n6. **Consult Strategist guidelines** — check `strategist_guidelines` block for optimization advice\n7. **Session-scoped lifecycle** — Companions exist for the session duration, not per-task\n\n---\n\n## Skill Authority (Critical Responsibility)\n\nYou are the **sole authority** for skill discovery and assignment in DCF+. This parallels the Planner's role in Phase 1, but operates dynamically rather than at workflow creation time.\n\n### Your Responsibilities\n\n| Responsibility | Description |\n|----------------|-------------|\n| **Discover** | Use `get_skillset()` to find available capabilities |\n| **Select** | Choose appropriate skills for each task based on requirements |\n| **Assign** | Include `required_skills` in every task delegation |\n| **Improve** | Apply Strategist's `skill_preferences` to make better choices |\n\n### Skill Selection Flow\n\n```\n1. Strategist observes task outcomes\n      ↓\n2. Strategist publishes skill_preferences to guidelines\n      ↓\n3. You read skill_preferences before delegating\n      ↓\n4. You select skills (preferring Strategist recommendations)\n      ↓\n5. You include required_skills in delegate_task()\n      ↓\n6. Companion loads exactly what you specified\n      ↓\n7. Companion executes and reports results\n      ↓\n8. Strategist observes outcome → loop continues\n```\n\n### Why Companions Don't Discover Skills\n\nCompanions are **simple executors** by design:\n- They load skills you assign — no second-guessing\n- They don't call `get_skillset()` — that's your job\n- They trust your skill decisions completely\n- This keeps Companions lightweight and predictable\n\n### Consulting Strategist Before Skill Selection\n\nBefore selecting skills for a task, **always check** `strategist_guidelines.skill_preferences`:\n\n```json\n{\n  \"skill_preferences\": {\n    \"research\": \"skill://research.web@0.2.0\",\n    \"data_analysis\": \"skill://analysis.data@0.1.0\",\n    \"summarization\": \"skill://writing.summarize@0.1.0\"\n  }\n}\n```\n\nIf the Strategist recommends a skill for a task type, **prefer that skill** unless you have a specific reason not to. The Strategist's recommendations are based on observed success rates across many task executions.\n\n## Environment\n- Container paths: use absolute paths under `/app`\n- Session data: `/app/sessions/<session_id>/`\n- Letta base URL: `http://letta:8283` (default)\n\n---\n\n## Memory Architecture\n\n### Your Memory Blocks\n\n| Label | Shared | Purpose |\n|-------|--------|---------|\n| `persona` | No | Your identity and behavior guidelines |\n| `session_context` | Yes | Shared session state (attached to all Companions) |\n| `strategist_guidelines` | Yes | Recommendations from Strategist (read-only for you) |\n| `companion_registry` | No | Local tracking of active Companions |\n\n### Shared Session Context\nThe `session_context` block is attached to you and all Companions. It contains:\n```json\n{\n  \"session_id\": \"uuid\",\n  \"conductor_id\": \"your_agent_id\",\n  \"objective\": \"User's current goal\",\n  \"state\": \"active|paused|completing|completed\",\n  \"companion_count\": N,\n  \"active_tasks\": [\"task_id_1\", ...],\n  \"completed_tasks\": [\"task_id_1\", ...],\n  \"shared_data\": { ... },\n  \"announcements\": [{ \"timestamp\": \"...\", \"message\": \"...\" }]\n}\n```\n\n**Update via**: `update_session_context(...)`\n\n---\n\n## Phase 1: Session Initialization\n\nWhen starting a new conversation session:\n\n### 1.1 Generate Session ID\n```python\nsession_id = str(uuid.uuid4())\n```\n\n### 1.2 Create Session Context\n```\ncreate_session_context(\n  session_id=<id>,\n  conductor_id=<your_agent_id>,\n  objective=\"Initial objective from user\",\n  initial_context_json=<optional_json>\n)\n```\n\nThis creates the shared `session_context` block and attaches it to you.\n\n### 1.3 Create Initial Companion(s)\nStart with 1-2 generalist Companions:\n```\ncreate_companion(\n  session_id=<id>,\n  conductor_id=<your_agent_id>,\n  specialization=\"generalist\",\n  shared_block_ids_json='[\"<session_context_block_id>\"]'\n)\n```\n\n---\n\n## Phase 2: Conversation & Task Identification\n\n### 2.1 Engage with User\n- Understand immediate needs\n- Identify tasks that can be delegated\n- Gather necessary context/inputs\n\n### 2.2 Check Strategist Guidelines\nBefore delegating, review `strategist_guidelines` for:\n- **skill_preferences**: Which skills work best for task types\n- **recommendations**: Recent advice from Strategist\n- **companion_scaling**: When to add/remove Companions\n\n### 2.3 Discover Available Skills (Your Core Responsibility)\n\nAs the **skill authority**, you must discover what capabilities are available:\n```\nget_skillset(include_previews=True)\n```\nOr with catalog:\n```\nget_skillset_from_catalog(include_previews=True)\n```\n\n**Skill selection process**:\n1. Identify task type (research, analysis, writing, etc.)\n2. Check `strategist_guidelines.skill_preferences` for recommendations\n3. If Strategist recommends a skill for this task type, prefer it\n4. Otherwise, select based on skill descriptions and requirements\n5. Verify skill permissions (egress, secrets) match task needs\n\n---\n\n## Phase 3: Task Delegation\n\n### 3.1 Check Companion Availability\n```\nlist_session_companions(\n  session_id=<id>,\n  include_status=True\n)\n```\n\n| Condition | Action |\n|-----------|--------|\n| Idle Companion available | Delegate to existing Companion |\n| All Companions busy | Create new Companion (if under limit) or wait |\n| Specialist needed | Create specialized Companion or find matching |\n\n### 3.2 Delegate to Specific Companion\n\n**Important**: You MUST specify `required_skills_json` — Companions don't discover skills themselves.\n\n```\ndelegate_task(\n  conductor_id=<your_agent_id>,\n  companion_id=<target_companion_id>,\n  task_description=\"Detailed task description\",\n  required_skills_json='[\"skill://research.web@0.2.0\"]',  # REQUIRED - you decide the skills\n  input_data_json='{\"query\": \"...\", \"constraints\": {...}}',\n  priority=\"normal\",\n  timeout_seconds=300\n)\n```\n\nThe Companion will load exactly the skills you specify and execute the task using those capabilities.\n\n### 3.3 Or Broadcast to Available Companions\nWhen any idle Companion can handle the task:\n```\nbroadcast_task(\n  conductor_id=<your_agent_id>,\n  session_id=<id>,\n  task_description=\"Task description\",\n  status_filter=\"idle\",\n  max_companions=1\n)\n```\n\n### 3.4 Update Session Context\nTrack active tasks:\n```\nupdate_session_context(\n  session_id=<id>,\n  block_id=<session_context_block_id>,\n  add_active_task=<task_id>\n)\n```\n\n---\n\n## Phase 4: Result Handling\n\n### 4.1 Receive Task Results\nCompanions send results via `send_message_to_agent_async`. Expect:\n```json\n{\n  \"type\": \"task_result\",\n  \"task_id\": \"uuid\",\n  \"status\": \"succeeded|failed\",\n  \"output\": { \"summary\": \"...\", \"data\": {...} },\n  \"metrics\": { \"duration_s\": N, \"tool_calls\": N },\n  \"companion_id\": \"uuid\",\n  \"completed_at\": \"ISO-8601\"\n}\n```\n\n### 4.2 Process Results\n| Result Status | Action |\n|---------------|--------|\n| `succeeded` | Present to user, mark task complete |\n| `failed` | Analyze error, retry/escalate/inform user |\n\n### 4.3 Update Session Context\n```\nupdate_session_context(\n  session_id=<id>,\n  block_id=<session_context_block_id>,\n  complete_task=<task_id>\n)\n```\n\n### 4.4 Present to User\n- Summarize result concisely\n- Provide key outputs/artifacts\n- Ask follow-up questions if needed\n\n---\n\n## Phase 5: Companion Management\n\n### 5.1 Scaling Companions\n\n**Scale Up** when:\n- Multiple tasks pending and all Companions busy\n- Specialized task requires different expertise\n- Strategist recommends more capacity\n\n```\ncreate_companion(\n  session_id=<id>,\n  conductor_id=<your_agent_id>,\n  specialization=\"research\",  # or appropriate specialty\n  shared_block_ids_json='[\"<session_context_block_id>\"]'\n)\n```\n\n**Scale Down** when:\n- Session winding down\n- Companion idle for extended period\n- Strategist recommends reduction\n\n```\ndismiss_companion(\n  companion_id=<id>,\n  unload_skills=True,\n  detach_shared_blocks=True\n)\n```\n\n### 5.2 Specialization Evolution\n\nBased on usage patterns, Companions can specialize:\n```\nupdate_companion_status(\n  companion_id=<id>,\n  specialization=\"analysis\"  # evolved from \"generalist\"\n)\n```\n\nConsult `strategist_guidelines.companion_scaling` for recommendations.\n\n### 5.3 Monitor Companion Health\nPeriodically check:\n```\nlist_session_companions(session_id=<id>, include_status=True)\n```\n\nHandle error states:\n- Restart stuck Companions\n- Redistribute tasks from failed Companions\n\n---\n\n## Phase 6: Session Finalization\n\nWhen the user session ends:\n\n### 6.1 Announce Session Ending\n```\nupdate_session_context(\n  session_id=<id>,\n  block_id=<session_context_block_id>,\n  state=\"completing\",\n  announcement=\"Session ending - collecting final results\"\n)\n```\n\n### 6.2 Finalize Session\n```\nfinalize_session(\n  session_id=<id>,\n  session_context_block_id=<block_id>,\n  delete_companions=True,\n  delete_session_block=False,\n  preserve_wisdom=True\n)\n```\n\nThis will:\n- Collect wisdom from each Companion (task history, learnings)\n- Dismiss all Companions\n- Update session state to \"completed\"\n\n### 6.3 Present Session Summary\n- Total tasks completed\n- Key outcomes achieved\n- Any unresolved items\n\n---\n\n## Communication Protocols\n\n### Delegating to Companion (via delegate_task)\nThe delegation message structure:\n```json\n{\n  \"type\": \"task_delegation\",\n  \"task_id\": \"uuid\",\n  \"from_conductor\": \"<your_agent_id>\",\n  \"timestamp\": \"ISO-8601\",\n  \"task\": {\n    \"description\": \"...\",\n    \"required_skills\": [\"skill://...\"],\n    \"input\": { ... },\n    \"priority\": \"normal|high|urgent\",\n    \"timeout_seconds\": 300\n  },\n  \"instructions\": \"Execute and report results back.\"\n}\n```\n\n### Broadcasting Announcements\nFor session-wide updates, use `update_session_context` with `announcement`:\n```\nupdate_session_context(\n  session_id=<id>,\n  block_id=<block_id>,\n  announcement=\"Priority change: focus on research tasks\"\n)\n```\n\nAll Companions with the shared block will see the announcement.\n\n---\n\n## Strategist Integration\n\nThe **Strategist** is to you what the **Reflector** is to the Phase 1 Planner — an observing agent that analyzes outcomes and provides recommendations to improve your decisions over time.\n\n### The Feedback Loop\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    Continuous Improvement                    │\n└─────────────────────────────────────────────────────────────┘\n     You delegate tasks    →    Companions execute & report\n            ↑                              ↓\n     You apply guidelines    ←    Strategist observes & analyzes\n```\n\n| Phase 1 (DCF) | Phase 2 (DCF+) |\n|---------------|----------------|\n| Reflector observes workflow results | Strategist observes session activity |\n| Reflector writes `reflector_guidelines` | Strategist writes `strategist_guidelines` |\n| Planner reads guidelines before planning | You read guidelines before delegating |\n| Post-workflow analysis (batch) | Real-time analysis (continuous) |\n\n### Reading Guidelines\nCheck `strategist_guidelines` block for:\n```json\n{\n  \"recommendations\": [\n    { \"timestamp\": \"...\", \"text\": \"...\" }\n  ],\n  \"skill_preferences\": {\n    \"research\": \"skill://research.web@0.2.0\",\n    \"analysis\": \"skill://analysis.data@0.1.0\"\n  },\n  \"companion_scaling\": {\n    \"min_companions\": 1,\n    \"max_companions\": 5,\n    \"scale_up_threshold\": 3,\n    \"scale_down_threshold\": 0\n  }\n}\n```\n\n### Acting on Recommendations\n- **Skill preferences**: Use recommended skills for task types — the Strategist knows what works\n- **Scaling thresholds**: Follow Companion scaling advice based on observed patterns\n- **Warnings**: Heed warnings about problematic skills or patterns\n- **Trust the feedback**: The Strategist's advice is evidence-based from real executions\n\n---\n\n## Error Handling\n\n| Scenario | Response |\n|----------|----------|\n| Companion fails task | Analyze error, retry with same/different Companion, or escalate to user |\n| Companion unresponsive | Check status, dismiss if error state, create replacement |\n| All Companions busy | Queue task, inform user of delay, scale up if appropriate |\n| Skill not available | Inform user of capability gap, suggest alternatives |\n| Session context update fails | Retry, fall back to direct communication |\n\n---\n\n## Operational Guidelines\n\n| Topic | Guideline |\n|-------|-----------|\n| Concurrency | Delegate independent tasks in parallel |\n| Context sharing | Use shared blocks for global state, messages for task-specific data |\n| User transparency | Inform user when delegating, summarize results promptly |\n| Resource management | Dismiss idle Companions, respect scaling limits |\n| Error escalation | Surface blocking errors to user; handle transient errors silently |\n\n## Output Style\n- **Conversation**: Natural, helpful, concise\n- **Delegation**: Clear task descriptions with sufficient context\n- **Results**: Summarize outcomes, highlight key findings\n- **Errors**: Explain impact, offer alternatives or next steps",
      "limit": 20000,
      "project_id": null,
      "template_name": null,
      "is_template": false,
      "template_id": null,
      "base_template_id": null,
      "deployment_id": null,
      "entity_id": null,
      "preserve_on_migration": false,
      "label": "persona",
      "read_only": false,
      "description": "The persona block: Stores details about your current persona, guiding how you behave and respond. This helps you to maintain consistency and personality in your interactions.",
      "metadata": {},
      "hidden": null,
      "id": "block-1"
    }
  ],
  "files": [],
  "sources": [],
  "tools": [
    {
      "id": "tool-21",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "broadcast_task",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def broadcast_task(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "broadcast_task",
        "description": "",
        "parameters": {
          "properties": {
            "conductor_id": {
              "title": "Conductor Id",
              "type": "string"
            },
            "session_id": {
              "title": "Session Id",
              "type": "string"
            },
            "task_description": {
              "title": "Task Description",
              "type": "string"
            },
            "specialization_filter": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Specialization Filter"
            },
            "status_filter": {
              "default": "idle",
              "title": "Status Filter",
              "type": "string"
            },
            "required_skills_json": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Required Skills Json"
            },
            "input_data_json": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Input Data Json"
            },
            "max_companions": {
              "default": 1,
              "title": "Max Companions",
              "type": "integer"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "conductor_id",
            "session_id",
            "task_description",
            "request_heartbeat"
          ],
          "title": "broadcast_taskArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "55ff8af43d5d"
      },
      "project_id": null
    },
    {
      "id": "tool-1",
      "tool_type": "letta_core",
      "description": "Search prior conversation history using hybrid search (text + semantic similarity).\n\nExamples:\n        # Search all messages\n        conversation_search(query=\"project updates\")\n\n        # Search only assistant messages\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\n\n        # Search with date range (inclusive of both dates)\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\n\n        # Search messages from a specific day (inclusive)\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\n        # This includes ALL messages from September 4, 2024\n\n        # Search with specific time boundaries\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\n\n        # Search with limit\n        conversation_search(query=\"debugging\", limit=10)\n\n    Returns:\n        str: Query result string containing matching messages with timestamps and content.",
      "source_type": "python",
      "name": "conversation_search",
      "tags": [
        "letta_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "conversation_search",
        "description": "Search prior conversation history using hybrid search (text + semantic similarity).\n\nExamples:\n        # Search all messages\n        conversation_search(query=\"project updates\")\n\n        # Search only assistant messages\n        conversation_search(query=\"error handling\", roles=[\"assistant\"])\n\n        # Search with date range (inclusive of both dates)\n        conversation_search(query=\"meetings\", start_date=\"2024-01-15\", end_date=\"2024-01-20\")\n        # This includes all messages from Jan 15 00:00:00 through Jan 20 23:59:59\n\n        # Search messages from a specific day (inclusive)\n        conversation_search(query=\"bug reports\", start_date=\"2024-09-04\", end_date=\"2024-09-04\")\n        # This includes ALL messages from September 4, 2024\n\n        # Search with specific time boundaries\n        conversation_search(query=\"deployment\", start_date=\"2024-01-15T09:00\", end_date=\"2024-01-15T17:30\")\n        # This includes messages from 9 AM to 5:30 PM on Jan 15\n\n        # Search with limit\n        conversation_search(query=\"debugging\", limit=10)\n\n    Returns:\n        str: Query result string containing matching messages with timestamps and content.",
        "parameters": {
          "type": "object",
          "properties": {
            "query": {
              "type": "string",
              "description": "String to search for using both text matching and semantic similarity."
            },
            "roles": {
              "type": "array",
              "items": {
                "type": "string",
                "enum": [
                  "assistant",
                  "user",
                  "tool"
                ]
              },
              "description": "Optional list of message roles to filter by."
            },
            "limit": {
              "type": "integer",
              "description": "Maximum number of results to return. Uses system default if not specified."
            },
            "start_date": {
              "type": "string",
              "description": "Filter results to messages created on or after this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-15\"), includes messages starting from 00:00:00 of that day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-15\" (from start of Jan 15), \"2024-01-15T14:30\" (from 2:30 PM on Jan 15)."
            },
            "end_date": {
              "type": "string",
              "description": "Filter results to messages created on or before this date (INCLUSIVE). When using date-only format (e.g., \"2024-01-20\"), includes all messages from that entire day. ISO 8601 format: \"YYYY-MM-DD\" or \"YYYY-MM-DDTHH:MM\". Examples: \"2024-01-20\" (includes all of Jan 20), \"2024-01-20T17:00\" (up to 5 PM on Jan 20)."
            }
          },
          "required": [
            "query"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": true,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-5",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "create_companion",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def create_companion(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "create_companion",
        "description": "",
        "parameters": {
          "properties": {
            "session_id": {
              "title": "Session Id",
              "type": "string"
            },
            "conductor_id": {
              "title": "Conductor Id",
              "type": "string"
            },
            "specialization": {
              "default": "generalist",
              "title": "Specialization",
              "type": "string"
            },
            "shared_block_ids_json": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Shared Block Ids Json"
            },
            "initial_skills_json": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Initial Skills Json"
            },
            "companion_name": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Companion Name"
            },
            "persona_override": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Persona Override"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "session_id",
            "conductor_id",
            "request_heartbeat"
          ],
          "title": "create_companionArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "b82de99fe6cd"
      },
      "project_id": null
    },
    {
      "id": "tool-23",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "create_directory",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def create_directory(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "create_directory",
        "description": "",
        "parameters": {
          "properties": {
            "path": {
              "title": "Path",
              "type": "string"
            },
            "parents": {
              "default": true,
              "title": "Parents",
              "type": "boolean"
            },
            "exist_ok": {
              "default": true,
              "title": "Exist Ok",
              "type": "boolean"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "path",
            "request_heartbeat"
          ],
          "title": "create_directoryArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "6e32be4285b6"
      },
      "project_id": null
    },
    {
      "id": "tool-12",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "create_session_context",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def create_session_context(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "create_session_context",
        "description": "",
        "parameters": {
          "properties": {
            "session_id": {
              "title": "Session Id",
              "type": "string"
            },
            "conductor_id": {
              "title": "Conductor Id",
              "type": "string"
            },
            "objective": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Objective"
            },
            "initial_context_json": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Initial Context Json"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "session_id",
            "conductor_id",
            "request_heartbeat"
          ],
          "title": "create_session_contextArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "a25e61206f24"
      },
      "project_id": null
    },
    {
      "id": "tool-13",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "delegate_task",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def delegate_task(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "delegate_task",
        "description": "",
        "parameters": {
          "properties": {
            "conductor_id": {
              "title": "Conductor Id",
              "type": "string"
            },
            "companion_id": {
              "title": "Companion Id",
              "type": "string"
            },
            "task_description": {
              "title": "Task Description",
              "type": "string"
            },
            "required_skills_json": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Required Skills Json"
            },
            "input_data_json": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Input Data Json"
            },
            "priority": {
              "default": "normal",
              "title": "Priority",
              "type": "string"
            },
            "timeout_seconds": {
              "default": 300,
              "title": "Timeout Seconds",
              "type": "integer"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "conductor_id",
            "companion_id",
            "task_description",
            "request_heartbeat"
          ],
          "title": "delegate_taskArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "4617547c31e6"
      },
      "project_id": null
    },
    {
      "id": "tool-11",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "dismiss_companion",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def dismiss_companion(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "dismiss_companion",
        "description": "",
        "parameters": {
          "properties": {
            "companion_id": {
              "title": "Companion Id",
              "type": "string"
            },
            "unload_skills": {
              "default": true,
              "title": "Unload Skills",
              "type": "boolean"
            },
            "detach_shared_blocks": {
              "default": true,
              "title": "Detach Shared Blocks",
              "type": "boolean"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "companion_id",
            "request_heartbeat"
          ],
          "title": "dismiss_companionArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "464385948713"
      },
      "project_id": null
    },
    {
      "id": "tool-6",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "finalize_session",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def finalize_session(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "finalize_session",
        "description": "",
        "parameters": {
          "properties": {
            "session_id": {
              "title": "Session Id",
              "type": "string"
            },
            "session_context_block_id": {
              "title": "Session Context Block Id",
              "type": "string"
            },
            "delete_companions": {
              "default": true,
              "title": "Delete Companions",
              "type": "boolean"
            },
            "delete_session_block": {
              "default": false,
              "title": "Delete Session Block",
              "type": "boolean"
            },
            "preserve_wisdom": {
              "default": true,
              "title": "Preserve Wisdom",
              "type": "boolean"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "session_id",
            "session_context_block_id",
            "request_heartbeat"
          ],
          "title": "finalize_sessionArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "050dfe87dfef"
      },
      "project_id": null
    },
    {
      "id": "tool-9",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "get_skillset",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def get_skillset(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "get_skillset",
        "description": "",
        "parameters": {
          "properties": {
            "manifests_dir": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Manifests Dir"
            },
            "schema_path": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Schema Path"
            },
            "include_previews": {
              "default": true,
              "title": "Include Previews",
              "type": "boolean"
            },
            "preview_chars": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Preview Chars"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "title": "get_skillsetArguments",
          "type": "object",
          "additionalProperties": false,
          "required": [
            "request_heartbeat"
          ]
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "a5321ba1b347"
      },
      "project_id": null
    },
    {
      "id": "tool-15",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "list_directory",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def list_directory(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "list_directory",
        "description": "",
        "parameters": {
          "properties": {
            "path": {
              "default": ".",
              "title": "Path",
              "type": "string"
            },
            "recursive": {
              "default": false,
              "title": "Recursive",
              "type": "boolean"
            },
            "include_hidden": {
              "default": false,
              "title": "Include Hidden",
              "type": "boolean"
            },
            "max_entries": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Max Entries"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "title": "list_directoryArguments",
          "type": "object",
          "additionalProperties": false,
          "required": [
            "request_heartbeat"
          ]
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "6257d43f8e6e"
      },
      "project_id": null
    },
    {
      "id": "tool-19",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "list_session_companions",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def list_session_companions(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "list_session_companions",
        "description": "",
        "parameters": {
          "properties": {
            "session_id": {
              "title": "Session Id",
              "type": "string"
            },
            "include_status": {
              "default": true,
              "title": "Include Status",
              "type": "boolean"
            },
            "specialization_filter": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Specialization Filter"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "session_id",
            "request_heartbeat"
          ],
          "title": "list_session_companionsArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "75cd236cde6e"
      },
      "project_id": null
    },
    {
      "id": "tool-4",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "load_skill",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def load_skill(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "load_skill",
        "description": "",
        "parameters": {
          "properties": {
            "skill_json": {
              "title": "Skill Json",
              "type": "string"
            },
            "agent_id": {
              "title": "Agent Id",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "skill_json",
            "agent_id",
            "request_heartbeat"
          ],
          "title": "load_skillArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "1b3f45af035b"
      },
      "project_id": null
    },
    {
      "id": "tool-2",
      "tool_type": "letta_sleeptime_core",
      "description": "The memory_insert command allows you to insert text at a specific location in a memory block.\n\nExamples:\n        # Update a block containing information about the user (append to the end of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\")\n\n        # Update a block containing information about the user (insert at the beginning of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\", insert_line=0)\n\n    Returns:\n        Optional[str]: None is always returned as this function does not produce a response.",
      "source_type": "python",
      "name": "memory_insert",
      "tags": [
        "letta_sleeptime_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "memory_insert",
        "description": "The memory_insert command allows you to insert text at a specific location in a memory block.\n\nExamples:\n        # Update a block containing information about the user (append to the end of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\")\n\n        # Update a block containing information about the user (insert at the beginning of the block)\n        memory_insert(label=\"customer\", new_str=\"The customer's ticket number is 12345\", insert_line=0)\n\n    Returns:\n        Optional[str]: None is always returned as this function does not produce a response.",
        "parameters": {
          "type": "object",
          "properties": {
            "label": {
              "type": "string",
              "description": "Section of the memory to be edited, identified by its label."
            },
            "new_str": {
              "type": "string",
              "description": "The text to insert. Do not include line number prefixes."
            },
            "insert_line": {
              "type": "integer",
              "description": "The line number after which to insert the text (0 for beginning of file). Defaults to -1 (end of the file)."
            }
          },
          "required": [
            "label",
            "new_str"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-0",
      "tool_type": "letta_sleeptime_core",
      "description": "The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\n\nDo NOT attempt to replace long strings, e.g. do not attempt to replace the entire contents of a memory block with a new string.\n\nExamples:\n        # Update a block containing information about the user\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n        # Update a block containing a todo list\n        memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\n\n        # Pass an empty string to\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\n\n        # Bad example - do NOT add (view-only) line numbers to the args\n        memory_replace(label=\"human\", old_str=\"1: Their name is Alice\", new_str=\"1: Their name is Bob\")\n\n        # Bad example - do NOT include the line number warning either\n        memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below (with arrows like '1→') are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\n1→ Their name is Alice\", new_str=\"1→ Their name is Bob\")\n\n        # Good example - no line numbers or line number warning (they are view-only), just the text\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n    Returns:\n        str: The success message",
      "source_type": "python",
      "name": "memory_replace",
      "tags": [
        "letta_sleeptime_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "memory_replace",
        "description": "The memory_replace command allows you to replace a specific string in a memory block with a new string. This is used for making precise edits.\n\nDo NOT attempt to replace long strings, e.g. do not attempt to replace the entire contents of a memory block with a new string.\n\nExamples:\n        # Update a block containing information about the user\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n        # Update a block containing a todo list\n        memory_replace(label=\"todos\", old_str=\"- [ ] Step 5: Search the web\", new_str=\"- [x] Step 5: Search the web\")\n\n        # Pass an empty string to\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"\")\n\n        # Bad example - do NOT add (view-only) line numbers to the args\n        memory_replace(label=\"human\", old_str=\"1: Their name is Alice\", new_str=\"1: Their name is Bob\")\n\n        # Bad example - do NOT include the line number warning either\n        memory_replace(label=\"human\", old_str=\"# NOTE: Line numbers shown below (with arrows like '1→') are to help during editing. Do NOT include line number prefixes in your memory edit tool calls.\\n1→ Their name is Alice\", new_str=\"1→ Their name is Bob\")\n\n        # Good example - no line numbers or line number warning (they are view-only), just the text\n        memory_replace(label=\"human\", old_str=\"Their name is Alice\", new_str=\"Their name is Bob\")\n\n    Returns:\n        str: The success message",
        "parameters": {
          "type": "object",
          "properties": {
            "label": {
              "type": "string",
              "description": "Section of the memory to be edited, identified by its label."
            },
            "old_str": {
              "type": "string",
              "description": "The text to replace (must match exactly, including whitespace and indentation)."
            },
            "new_str": {
              "type": "string",
              "description": "The new text to insert in place of the old text. Do not include line number prefixes."
            }
          },
          "required": [
            "label",
            "old_str",
            "new_str"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-22",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "read_file",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def read_file(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "read_file",
        "description": "",
        "parameters": {
          "properties": {
            "path": {
              "title": "Path",
              "type": "string"
            },
            "offset": {
              "default": 0,
              "title": "Offset",
              "type": "integer"
            },
            "length": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Length"
            },
            "encoding": {
              "default": "utf-8",
              "title": "Encoding",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "path",
            "request_heartbeat"
          ],
          "title": "read_fileArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "dcedb83234d3"
      },
      "project_id": null
    },
    {
      "id": "tool-7",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "read_session_activity",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def read_session_activity(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "read_session_activity",
        "description": "",
        "parameters": {
          "properties": {
            "session_id": {
              "title": "Session Id",
              "type": "string"
            },
            "session_context_block_id": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Session Context Block Id"
            },
            "include_companion_details": {
              "default": true,
              "title": "Include Companion Details",
              "type": "boolean"
            },
            "include_task_history": {
              "default": true,
              "title": "Include Task History",
              "type": "boolean"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "session_id",
            "request_heartbeat"
          ],
          "title": "read_session_activityArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "b2e615142299"
      },
      "project_id": null
    },
    {
      "id": "tool-17",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "remove_tool_return_limits",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def remove_tool_return_limits(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "remove_tool_return_limits",
        "description": "",
        "parameters": {
          "properties": {
            "agent_id": {
              "title": "Agent Id",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "agent_id",
            "request_heartbeat"
          ],
          "title": "remove_tool_return_limitsArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "14b80d2184f5"
      },
      "project_id": null
    },
    {
      "id": "tool-3",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "resolve_agent_name_to_id",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def resolve_agent_name_to_id(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "resolve_agent_name_to_id",
        "description": "",
        "parameters": {
          "properties": {
            "agent_name": {
              "title": "Agent Name",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "agent_name",
            "request_heartbeat"
          ],
          "title": "resolve_agent_name_to_idArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "5255008f8ca1"
      },
      "project_id": null
    },
    {
      "id": "tool-16",
      "tool_type": "letta_multi_agent_core",
      "description": "Sends a message to a specific Letta agent within the same organization. The sender's identity is automatically included, so no explicit introduction is required in the message. This function does not expect a response from the target agent, making it suitable for notifications or one-way communication.",
      "source_type": "python",
      "name": "send_message_to_agent_async",
      "tags": [
        "letta_multi_agent_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "send_message_to_agent_async",
        "description": "Sends a message to a specific Letta agent within the same organization. The sender's identity is automatically included, so no explicit introduction is required in the message. This function does not expect a response from the target agent, making it suitable for notifications or one-way communication.",
        "parameters": {
          "type": "object",
          "properties": {
            "message": {
              "type": "string",
              "description": "The content of the message to be sent to the target agent."
            },
            "other_agent_id": {
              "type": "string",
              "description": "The unique identifier of the target Letta agent."
            }
          },
          "required": [
            "message",
            "other_agent_id"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-8",
      "tool_type": "letta_multi_agent_core",
      "description": "Sends a message to all agents within the same organization that match the specified tag criteria. Agents must possess *all* of the tags in `match_all` and *at least one* of the tags in `match_some` to receive the message.",
      "source_type": "python",
      "name": "send_message_to_agents_matching_tags",
      "tags": [
        "letta_multi_agent_core"
      ],
      "source_code": null,
      "json_schema": {
        "name": "send_message_to_agents_matching_tags",
        "description": "Sends a message to all agents within the same organization that match the specified tag criteria. Agents must possess *all* of the tags in `match_all` and *at least one* of the tags in `match_some` to receive the message.",
        "parameters": {
          "type": "object",
          "properties": {
            "message": {
              "type": "string",
              "description": "The content of the message to be sent to each matching agent."
            },
            "match_all": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "A list of tags that an agent must possess to receive the message."
            },
            "match_some": {
              "type": "array",
              "items": {
                "type": "string"
              },
              "description": "A list of tags where an agent must have at least one to qualify."
            }
          },
          "required": [
            "message",
            "match_all",
            "match_some"
          ]
        }
      },
      "args_json_schema": null,
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {},
      "project_id": null
    },
    {
      "id": "tool-10",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "unload_skill",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def unload_skill(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "unload_skill",
        "description": "",
        "parameters": {
          "properties": {
            "manifest_id": {
              "title": "Manifest Id",
              "type": "string"
            },
            "agent_id": {
              "title": "Agent Id",
              "type": "string"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "manifest_id",
            "agent_id",
            "request_heartbeat"
          ],
          "title": "unload_skillArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "885a7f6a1164"
      },
      "project_id": null
    },
    {
      "id": "tool-20",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "update_session_context",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def update_session_context(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "update_session_context",
        "description": "",
        "parameters": {
          "properties": {
            "session_id": {
              "title": "Session Id",
              "type": "string"
            },
            "block_id": {
              "title": "Block Id",
              "type": "string"
            },
            "state": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "State"
            },
            "objective": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Objective"
            },
            "add_active_task": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Add Active Task"
            },
            "complete_task": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Complete Task"
            },
            "companion_count": {
              "anyOf": [
                {
                  "type": "integer"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Companion Count"
            },
            "announcement": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Announcement"
            },
            "shared_data_json": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Shared Data Json"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "session_id",
            "block_id",
            "request_heartbeat"
          ],
          "title": "update_session_contextArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "467a93f83586"
      },
      "project_id": null
    },
    {
      "id": "tool-18",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "validate_skill_manifest",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def validate_skill_manifest(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "validate_skill_manifest",
        "description": "",
        "parameters": {
          "properties": {
            "skill_json": {
              "title": "Skill Json",
              "type": "string"
            },
            "schema_path": {
              "anyOf": [
                {
                  "type": "string"
                },
                {
                  "type": "null"
                }
              ],
              "default": null,
              "title": "Schema Path"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "skill_json",
            "request_heartbeat"
          ],
          "title": "validate_skill_manifestArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "775b52c3d7af"
      },
      "project_id": null
    },
    {
      "id": "tool-14",
      "tool_type": "external_mcp",
      "description": "",
      "source_type": "python",
      "name": "write_file",
      "tags": [
        "mcp:DCF"
      ],
      "source_code": "def write_file(**kwargs):\n    raise RuntimeError(\"Something went wrong - we should never be using the persisted source code for MCP. Please reach out to Letta team\")",
      "json_schema": {
        "name": "write_file",
        "description": "",
        "parameters": {
          "properties": {
            "path": {
              "title": "Path",
              "type": "string"
            },
            "content": {
              "title": "Content",
              "type": "string"
            },
            "append": {
              "default": false,
              "title": "Append",
              "type": "boolean"
            },
            "encoding": {
              "default": "utf-8",
              "title": "Encoding",
              "type": "string"
            },
            "create_parents": {
              "default": true,
              "title": "Create Parents",
              "type": "boolean"
            },
            "request_heartbeat": {
              "type": "boolean",
              "description": "Request an immediate heartbeat after function execution. You MUST set this value to `True` if you want to send a follow-up message or run a follow-up tool call (chain multiple tools together). If set to `False` (the default), then the chain of execution will end immediately after this function call."
            }
          },
          "required": [
            "path",
            "content",
            "request_heartbeat"
          ],
          "title": "write_fileArguments",
          "type": "object",
          "additionalProperties": false
        },
        "mcp:SCHEMA_STATUS": "STRICT_COMPLIANT",
        "mcp:SCHEMA_WARNINGS": []
      },
      "args_json_schema": {},
      "return_char_limit": 50000,
      "pip_requirements": null,
      "npm_requirements": null,
      "default_requires_approval": null,
      "enable_parallel_execution": false,
      "created_by_id": "user-00000000-0000-4000-8000-000000000000",
      "last_updated_by_id": "user-00000000-0000-4000-8000-000000000000",
      "metadata_": {
        "mcp": {
          "server_name": "DCF",
          "server_id": "mcp_server-eff49008-dc83-4eaa-98a5-b50fa69fb24f"
        },
        "tool_hash": "cc347dae4c99"
      },
      "project_id": null
    }
  ],
  "mcp_servers": [
    {
      "id": "mcp_server-0",
      "server_type": "streamable_http",
      "server_name": "DCF",
      "server_url": "http://dcf-mcp:8337/mcp",
      "stdio_config": null,
      "metadata_": {}
    }
  ],
  "metadata": {
    "revision_id": "27de0f58e076"
  },
  "created_at": "2026-01-30T12:02:33.868224+00:00"
}